# Evaluation Results Comparison

| Model                      | Accuracy | Mean Squared Error |
|----------------------------|----------|--------------------|
| Fine-tuned gpt-4o-2024-08-06 | 0.56     | 0.21               |
| gpt-o Mini Model           | 0.44     | 0.35               |
| Latest gpt-o Model         | 0.54     | 0.23               |

This table presents the evaluation results for the different models used.
